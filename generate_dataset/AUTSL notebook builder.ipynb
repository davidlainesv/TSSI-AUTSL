{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd4fbdc-cec2-4b67-9161-174d96d0ade3",
   "metadata": {},
   "source": [
    "# Download and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd027a4-fbe4-4ca9-b0c5-6da79bbf84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user mediapipe\n",
    "# !pip install --user git+https://github.com/sign-language-processing/datasets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c089777-80d4-4ace-9156-9102a4275b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://raw.githubusercontent.com/davidlainesv/TSSI-WLASL100/test/skeleton_graph.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3203eb99-2572-4ec1-bb68-832982f3ced2",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc7f0b4-2fac-4344-afe5-f716140eb480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 11:12:09.370072: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 11:12:09.546890: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-25 11:12:12.112603: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-02-25 11:12:12.112848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-02-25 11:12:12.112870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import sign_language_datasets.datasets\n",
    "from sign_language_datasets.datasets.config import SignDatasetConfig\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf90cde0-03ed-4554-a430-18fa5f71513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Using custom data configuration only-poses\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'int32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int32.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.\n",
      "2023-02-25 11:12:16.896048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:16.909374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:16.911179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:16.914452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 11:12:16.915160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:16.916966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:16.918678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:17.660427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:17.662412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:17.664169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-25 11:12:17.665805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "config = SignDatasetConfig(name=\"only-poses\",\n",
    "                           version=\"1.0.0\",\n",
    "                           include_video=False,\n",
    "                           include_pose=\"holistic\",\n",
    "                           fps=30)\n",
    "autsl, info = tfds.load(name='autsl', data_dir=\"datasets\", builder_kwargs={\"config\": config}, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f7c165-31dc-4d96-b51a-101774d0c94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'validation'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autsl.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6161592e-868a-435e-9708-9f75092530fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signer21_sample22 (58, 1, 543, 4) 194\n",
      "signer8_sample1334 (67, 1, 543, 4) 10\n",
      "signer3_sample171 (57, 1, 543, 4) 116\n"
     ]
    }
   ],
   "source": [
    "ds_train = autsl[\"train\"]\n",
    "ds_validation = autsl[\"validation\"]\n",
    "ds_test = autsl[\"test\"]\n",
    "\n",
    "for datum in itertools.islice(ds_train, 0, 3):\n",
    "  print(\n",
    "      datum['id'].numpy().decode('utf-8'),\n",
    "      datum['pose']['data'].shape,\n",
    "      datum['gloss_id'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602a8b78-4d0c-4674-9278-dfd338ea5d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'gloss_id': int32,\n",
       "    'id': Text(shape=(), dtype=string),\n",
       "    'meaning': FeaturesDict({\n",
       "        'english': Text(shape=(), dtype=string),\n",
       "        'turkish': Text(shape=(), dtype=string),\n",
       "    }),\n",
       "    'pose': PoseFeature({'data': TensorInfo(shape=(None, 1, 543, 4), dtype=float32), 'conf': TensorInfo(shape=(None, 1, 543), dtype=float32), 'fps': TensorInfo(shape=(), dtype=int32)}),\n",
       "    'sample': int32,\n",
       "    'signer': int32,\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5f0437-65e5-45b2-be29-d027b2c0aef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess data and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76eeeea3-7de6-4cdd-bd55-ccb589f31369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signer21_sample22 (58, 135, 3) 194\n",
      "signer8_sample1334 (67, 135, 3) 10\n",
      "signer3_sample171 (57, 135, 3) 116\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import Preprocessing\n",
    "from skeleton_graph import tssi_v2\n",
    "\n",
    "tssi_order = tssi_v2()[1]\n",
    "pp = Preprocessing(tssi_order)\n",
    "\n",
    "def fn_map(example):\n",
    "    example[\"pose\"] = pp(example[\"pose\"][\"data\"])\n",
    "    return example\n",
    "\n",
    "ds_train_mapped = ds_train.map(fn_map)\n",
    "ds_validation_mapped = ds_validation.map(fn_map)\n",
    "ds_test_mapped = ds_test.map(fn_map)\n",
    "\n",
    "for datum in itertools.islice(ds_train_mapped, 0, 3):\n",
    "  print(\n",
    "      datum['id'].numpy().decode('utf-8'),\n",
    "      datum['pose'].shape,\n",
    "      datum['gloss_id'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "688012a4-03f9-4ddb-a847-a2b3de7c1eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Text(shape=(), dtype=string),\n",
       " 'signer': Tensor(shape=(), dtype=int32),\n",
       " 'sample': Tensor(shape=(), dtype=int32),\n",
       " 'gloss_id': Tensor(shape=(), dtype=int32),\n",
       " 'meaning': FeaturesDict({\n",
       "     'english': Text(shape=(), dtype=string),\n",
       "     'turkish': Text(shape=(), dtype=string),\n",
       " }),\n",
       " 'pose': Tensor(shape=(None, 135, 3), dtype=float32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features_dict_updated = dict(info.features)\n",
    "features_dict_updated['pose'] = tfds.features.Tensor(shape=(None, len(tssi_order), 3), dtype=np.float32)\n",
    "features_dict_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1547198-93cf-4e86-990c-4f22ad235d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'datasets/autsl_tssi': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r \"datasets/autsl_tssi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf20e86-ed1e-44a5-b861-0049c4669410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to datasets/autsl_tssi/1.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling datasets/autsl_tssi/1.0.0.incompleteI2PN6C/autsl_tssi-train.tfrecord*...:   0%|          | 0/28142 […"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling datasets/autsl_tssi/1.0.0.incompleteI2PN6C/autsl_tssi-validation.tfrecord*...:   0%|          | 0/44…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling datasets/autsl_tssi/1.0.0.incompleteI2PN6C/autsl_tssi-test.tfrecord*...:   0%|          | 0/3742 [00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset autsl_tssi downloaded and prepared to datasets/autsl_tssi/1.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_datasets.core.dataset_builders.adhoc_builder.AdhocBuilder at 0x7f2014203690>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optionally define a custom `data_dir`.\n",
    "# If None, then the default data dir is used.\n",
    "custom_data_dir = \"datasets\"\n",
    "\n",
    "# Define the builder.\n",
    "tfds.dataset_builders.store_as_tfds_dataset(\n",
    "    name=\"autsl_tssi\",\n",
    "    version=\"1.0.0\",\n",
    "    data_dir=custom_data_dir,\n",
    "    split_datasets={\n",
    "        \"train\": ds_train_mapped,\n",
    "        \"validation\": ds_validation_mapped,\n",
    "        \"test\": ds_test_mapped,\n",
    "    },\n",
    "    features=tfds.features.FeaturesDict(features_dict_updated),\n",
    "    description=\"AUTSL dataset in TSSI v2 format\",\n",
    "    release_notes={\n",
    "        \"1.0.0\": \"Initial release!\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e190c5-74d0-447a-8cd6-0fa8f1733c2e",
   "metadata": {},
   "source": [
    "# See results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6192e35b-ff1e-4ca4-8224-48dabcdc385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autsl_tssi, info = tfds.load(name='autsl_tssi', data_dir=\"datasets\", with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23260fc-3906-401c-ac2c-01cd2cc71505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autsl_tssi.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "129e1edf-8246-40c5-a610-adc7cf89ab11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signer12_sample160 (70, 135, 3) 59\n",
      "signer8_sample1194 (57, 135, 3) 163\n",
      "signer0_sample556 (42, 135, 3) 39\n"
     ]
    }
   ],
   "source": [
    "ds_train_tssi = autsl_tssi[\"train\"]\n",
    "ds_validation_tssi = autsl_tssi[\"validation\"]\n",
    "ds_test_tssi = autsl_tssi[\"test\"]\n",
    "\n",
    "for datum in itertools.islice(ds_train_tssi, 0, 3):\n",
    "  print(\n",
    "      datum['id'].numpy().decode('utf-8'),\n",
    "      datum['pose'].shape,\n",
    "      datum['gloss_id'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab7d324-eb9b-4e7a-bc9b-95cfa2417342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=28142>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train_tssi.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0df6da82-f6c4-4497-95ec-6a28b18ae9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=4418>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_validation_tssi.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32efaa5c-031f-4b5d-a7d3-3d9c2dab08e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=3742>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test_tssi.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0633b82-536d-40c4-9e25-eeac78b6428d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m103"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
